{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6cf8fd",
   "metadata": {
    "papermill": {
     "duration": 0.012685,
     "end_time": "2026-01-19T23:55:32.874174",
     "exception": false,
     "start_time": "2026-01-19T23:55:32.861489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 1: PyTorch Fundamentals & Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c012e",
   "metadata": {
    "papermill": {
     "duration": 0.011063,
     "end_time": "2026-01-19T23:55:32.897331",
     "exception": false,
     "start_time": "2026-01-19T23:55:32.886268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setup and Installation\n",
    "If you are running this locally, you'll need to install PyTorch first: pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6575d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:32.921575Z",
     "iopub.status.busy": "2026-01-19T23:55:32.921195Z",
     "iopub.status.idle": "2026-01-19T23:55:38.671403Z",
     "shell.execute_reply": "2026-01-19T23:55:38.670292Z"
    },
    "papermill": {
     "duration": 5.764754,
     "end_time": "2026-01-19T23:55:38.673559",
     "exception": false,
     "start_time": "2026-01-19T23:55:32.908805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ea42e",
   "metadata": {
    "papermill": {
     "duration": 0.011453,
     "end_time": "2026-01-19T23:55:38.696447",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.684994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Creating Tensors\n",
    "Tensors can be created from Python lists, NumPy arrays, or directly with built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ed0e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:38.720707Z",
     "iopub.status.busy": "2026-01-19T23:55:38.719648Z",
     "iopub.status.idle": "2026-01-19T23:55:38.815189Z",
     "shell.execute_reply": "2026-01-19T23:55:38.813636Z"
    },
    "papermill": {
     "duration": 0.110093,
     "end_time": "2026-01-19T23:55:38.817389",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.707296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 7, Dimensions: 0\n",
      "Vector: tensor([1, 2, 3]), Shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 1. From a list (Scalar)\n",
    "scalar = torch.tensor(7)\n",
    "print(f\"Scalar: {scalar}, Dimensions: {scalar.ndim}\")\n",
    "\n",
    "# 2. From a list (Vector)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(f\"Vector: {vector}, Shape: {vector.shape}\")\n",
    "\n",
    "# 3. From a NumPy array\n",
    "np_array = np.array([1.0, 2.0, 3.0])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "\n",
    "# 4. Common initializations\n",
    "zeros = torch.zeros((2, 3))    # 2x3 matrix of zeros\n",
    "ones = torch.ones((2, 3))      # 2x3 matrix of ones\n",
    "rand = torch.rand((3, 3))      # 3x3 matrix of random numbers [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030115d",
   "metadata": {
    "papermill": {
     "duration": 0.011131,
     "end_time": "2026-01-19T23:55:38.840251",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.829120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Tensor Operations\n",
    "Operations in PyTorch are nearly identical to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b7704a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:38.864740Z",
     "iopub.status.busy": "2026-01-19T23:55:38.864023Z",
     "iopub.status.idle": "2026-01-19T23:55:38.900802Z",
     "shell.execute_reply": "2026-01-19T23:55:38.899478Z"
    },
    "papermill": {
     "duration": 0.051812,
     "end_time": "2026-01-19T23:55:38.902945",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.851133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "Result shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Addition\n",
    "print(x + y) # or torch.add(x, y)\n",
    "\n",
    "# Matrix Multiplication (Crucial for Deep Learning)\n",
    "tensor_a = torch.rand(3, 2)\n",
    "tensor_b = torch.rand(2, 4)\n",
    "# Use @ or torch.matmul\n",
    "result = tensor_a @ tensor_b \n",
    "print(f\"Result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85b837",
   "metadata": {
    "papermill": {
     "duration": 0.011042,
     "end_time": "2026-01-19T23:55:38.925413",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.914371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Reshaping and Squeezing\n",
    "Often in ML, you need to change the \"shape\" of your data to fit into a model layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce59fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:38.949113Z",
     "iopub.status.busy": "2026-01-19T23:55:38.948781Z",
     "iopub.status.idle": "2026-01-19T23:55:38.960907Z",
     "shell.execute_reply": "2026-01-19T23:55:38.959615Z"
    },
    "papermill": {
     "duration": 0.026594,
     "end_time": "2026-01-19T23:55:38.963049",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.936455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "x_reshaped: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "x_view: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 10) # [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "x_reshaped = x.reshape(3, 3)\n",
    "\n",
    "# 'view' is similar to reshape but shares memory with the original tensor\n",
    "x_view = x.view(9, 1)\n",
    "\n",
    "print(\"x:\", x)\n",
    "\n",
    "print(\"x_reshaped:\", x_reshaped)\n",
    "\n",
    "print(\"x_view:\" ,x_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e50675",
   "metadata": {
    "papermill": {
     "duration": 0.011163,
     "end_time": "2026-01-19T23:55:38.985553",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.974390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Moving to GPU\n",
    "One of the main reasons we use PyTorch over NumPy is GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300a9af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.009648Z",
     "iopub.status.busy": "2026-01-19T23:55:39.009248Z",
     "iopub.status.idle": "2026-01-19T23:55:39.019940Z",
     "shell.execute_reply": "2026-01-19T23:55:39.018906Z"
    },
    "papermill": {
     "duration": 0.025032,
     "end_time": "2026-01-19T23:55:39.021905",
     "exception": false,
     "start_time": "2026-01-19T23:55:38.996873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "x_gpu: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move tensor to device\n",
    "x_gpu = x.to(device)\n",
    "\n",
    "print(\"x_gpu:\", x_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41c730",
   "metadata": {
    "papermill": {
     "duration": 0.010877,
     "end_time": "2026-01-19T23:55:39.044019",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.033142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 2: Autograd & The Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67434d64",
   "metadata": {
    "papermill": {
     "duration": 0.012384,
     "end_time": "2026-01-19T23:55:39.067581",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.055197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The requires_grad Flag\n",
    "By default, PyTorch tensors don't track their history. To calculate gradients, you must tell PyTorch that a tensor is part of a mathematical \"tree\" that needs to be differentiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99801e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.091678Z",
     "iopub.status.busy": "2026-01-19T23:55:39.091308Z",
     "iopub.status.idle": "2026-01-19T23:55:39.109066Z",
     "shell.execute_reply": "2026-01-19T23:55:39.107797Z"
    },
    "papermill": {
     "duration": 0.03249,
     "end_time": "2026-01-19T23:55:39.111339",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.078849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x: 2.0\n",
      "Output y: 9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor and tell it to track gradients\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define a function: y = x^2 + 5\n",
    "y = x**2 + 5\n",
    "\n",
    "print(f\"Input x: {x}\")\n",
    "print(f\"Output y: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c2d60",
   "metadata": {
    "papermill": {
     "duration": 0.011093,
     "end_time": "2026-01-19T23:55:39.133747",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.122654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Backpropagation (The .backward() call)\n",
    "When you call .backward(), PyTorch walks backward from the output to the input, calculating the derivative of the function at that specific point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f150b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.157718Z",
     "iopub.status.busy": "2026-01-19T23:55:39.157358Z",
     "iopub.status.idle": "2026-01-19T23:55:39.176144Z",
     "shell.execute_reply": "2026-01-19T23:55:39.174912Z"
    },
    "papermill": {
     "duration": 0.033344,
     "end_time": "2026-01-19T23:55:39.178268",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.144924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x: 4.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gradient (dy/dx)\n",
    "y.backward()\n",
    "\n",
    "# The gradient dy/dx = 2x. \n",
    "# Since x = 2, the gradient should be 2*(2) = 4.\n",
    "print(f\"Gradient of y with respect to x: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a7c72",
   "metadata": {
    "papermill": {
     "duration": 0.011415,
     "end_time": "2026-01-19T23:55:39.201145",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.189730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Preventing Gradient Tracking\n",
    "When you are evaluating a model (testing it), you don't want to calculate gradients because it wastes memory and speed. You use torch.no_grad()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b0f33c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.226032Z",
     "iopub.status.busy": "2026-01-19T23:55:39.225406Z",
     "iopub.status.idle": "2026-01-19T23:55:39.231226Z",
     "shell.execute_reply": "2026-01-19T23:55:39.230273Z"
    },
    "papermill": {
     "duration": 0.020784,
     "end_time": "2026-01-19T23:55:39.233362",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.212578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does z have a gradient function? None\n",
      "Does y have a gradient function? <AddBackward0 object at 0x7bdbaf5213c0>\n"
     ]
    }
   ],
   "source": [
    "# This is how you \"turn off\" the math tracking\n",
    "with torch.no_grad():\n",
    "    z = x * 2\n",
    "    print(f\"Does z have a gradient function? {z.grad_fn}\") # Returns None\n",
    "\n",
    "print(f\"Does y have a gradient function? {y.grad_fn}\") # Returns a Power object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e917ee2",
   "metadata": {
    "papermill": {
     "duration": 0.011677,
     "end_time": "2026-01-19T23:55:39.256969",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.245292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Zeroing Gradients\n",
    "In PyTorch, gradients accumulate (they add up) by default. This is a common source of bugs for beginners. You must clear them before calculating a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f625da25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.281761Z",
     "iopub.status.busy": "2026-01-19T23:55:39.280703Z",
     "iopub.status.idle": "2026-01-19T23:55:39.292108Z",
     "shell.execute_reply": "2026-01-19T23:55:39.290940Z"
    },
    "papermill": {
     "duration": 0.026234,
     "end_time": "2026-01-19T23:55:39.294434",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.268200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient after 1st run: 8.0\n",
      "Gradient after 2nd run (Accumulated!): 12.0\n",
      "Gradient after zeroing: 0.0\n"
     ]
    }
   ],
   "source": [
    "# If we run backward again without clearing...\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(f\"Gradient after 1st run: {x.grad}\")\n",
    "\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(f\"Gradient after 2nd run (Accumulated!): {x.grad}\") # It adds to the previous 4!\n",
    "\n",
    "# How to fix it:\n",
    "x.grad.zero_()\n",
    "print(f\"Gradient after zeroing: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c1f25",
   "metadata": {
    "papermill": {
     "duration": 0.011361,
     "end_time": "2026-01-19T23:55:39.317277",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.305916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 3: Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2750acf",
   "metadata": {
    "papermill": {
     "duration": 0.011341,
     "end_time": "2026-01-19T23:55:39.340038",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.328697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The Setup\n",
    "We want to model the relationship\n",
    "$y = wx + b$.$w$ (weight): \n",
    "The slope.$b$ (bias): The intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82307eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.365299Z",
     "iopub.status.busy": "2026-01-19T23:55:39.364270Z",
     "iopub.status.idle": "2026-01-19T23:55:39.380774Z",
     "shell.execute_reply": "2026-01-19T23:55:39.379615Z"
    },
    "papermill": {
     "duration": 0.031899,
     "end_time": "2026-01-19T23:55:39.383130",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.351231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial w: 0.3932, b: -0.2148\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Create 'True' data with some noise\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, 1) * 10\n",
    "# True relationship: y = 2x + 5\n",
    "y_true = 2 * X + 5 + torch.randn(100, 1) * 2 \n",
    "\n",
    "# 2. Initialize our parameters (Randomly)\n",
    "# We set requires_grad=True because we want to optimize these!\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "print(f\"Initial w: {w.item():.4f}, b: {b.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c05ae5",
   "metadata": {
    "papermill": {
     "duration": 0.011423,
     "end_time": "2026-01-19T23:55:39.405983",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.394560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. The Training Loop\n",
    "To \"learn,\" we repeat four steps:Forward Pass: Predict $y$ using current $w$ and $b$.Loss Calculation: Calculate the Mean Squared Error (MSE).Backward Pass: Use .backward() to find the gradients.Optimization: Update $w$ and $b$ by moving in the opposite direction of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bcfbec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.431395Z",
     "iopub.status.busy": "2026-01-19T23:55:39.430711Z",
     "iopub.status.idle": "2026-01-19T23:55:39.478937Z",
     "shell.execute_reply": "2026-01-19T23:55:39.477766Z"
    },
    "papermill": {
     "duration": 0.06356,
     "end_time": "2026-01-19T23:55:39.480951",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.417391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 35.3256\n",
      "Epoch 20: Loss = 28.9034\n",
      "Epoch 30: Loss = 27.8249\n",
      "Epoch 40: Loss = 26.8579\n",
      "Epoch 50: Loss = 25.9297\n",
      "Epoch 60: Loss = 25.0378\n",
      "Epoch 70: Loss = 24.1807\n",
      "Epoch 80: Loss = 23.3572\n",
      "Epoch 90: Loss = 22.5659\n",
      "Epoch 100: Loss = 21.8055\n",
      "\n",
      "Final Learned w: 2.0294, b: 0.7495\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 # Learning Rate\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward Pass\n",
    "    y_pred = X * w + b\n",
    "    \n",
    "    # 2. Compute Loss (Mean Squared Error)\n",
    "    loss = torch.mean((y_pred - y_true)**2)\n",
    "    \n",
    "    # 3. Backward Pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4. Update Parameters\n",
    "    # Wrap in no_grad because updating weights shouldn't be tracked in the graph\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        \n",
    "        # IMPORTANT: Manually zero the gradients for the next epoch\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(f\"\\nFinal Learned w: {w.item():.4f}, b: {b.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9daa7",
   "metadata": {
    "papermill": {
     "duration": 0.01165,
     "end_time": "2026-01-19T23:55:39.504394",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.492744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Visualizing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c32fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.529889Z",
     "iopub.status.busy": "2026-01-19T23:55:39.529174Z",
     "iopub.status.idle": "2026-01-19T23:55:39.806497Z",
     "shell.execute_reply": "2026-01-19T23:55:39.805622Z"
    },
    "papermill": {
     "duration": 0.292539,
     "end_time": "2026-01-19T23:55:39.808547",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.516008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X.numpy(), y_true.numpy(), label=\"Data\")\n",
    "plt.plot(X.numpy(), (X * w + b).detach().numpy(), color='red', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65bc05c",
   "metadata": {
    "papermill": {
     "duration": 0.01213,
     "end_time": "2026-01-19T23:55:39.832572",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.820442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 4: The PyTorch Workflow (nn.Module & Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f89b4",
   "metadata": {
    "papermill": {
     "duration": 0.011766,
     "end_time": "2026-01-19T23:55:39.856095",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.844329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Defining the Model\n",
    "In PyTorch, all neural networks must inherit from torch.nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4929dc0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.881318Z",
     "iopub.status.busy": "2026-01-19T23:55:39.880934Z",
     "iopub.status.idle": "2026-01-19T23:55:39.909908Z",
     "shell.execute_reply": "2026-01-19T23:55:39.908546Z"
    },
    "papermill": {
     "duration": 0.044257,
     "end_time": "2026-01-19T23:55:39.912107",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.867850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0098]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7605], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn # nn contains all the building blocks\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of manual w and b, we use nn.Linear\n",
    "        # 1 input feature (x), 1 output feature (y)\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # This defines the computation performed at every call\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegressionModel()\n",
    "print(list(model.parameters())) # PyTorch automatically created w and b for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83207d7",
   "metadata": {
    "papermill": {
     "duration": 0.012219,
     "end_time": "2026-01-19T23:55:39.937287",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.925068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Loss Function and Optimizer\n",
    "Instead of writing the MSE math ourselves and manually subtracting gradients, we use built-in tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3418043a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:39.963054Z",
     "iopub.status.busy": "2026-01-19T23:55:39.962679Z",
     "iopub.status.idle": "2026-01-19T23:55:47.234201Z",
     "shell.execute_reply": "2026-01-19T23:55:47.232996Z"
    },
    "papermill": {
     "duration": 7.287193,
     "end_time": "2026-01-19T23:55:47.236478",
     "exception": false,
     "start_time": "2026-01-19T23:55:39.949285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Setup a Loss Function\n",
    "loss_fn = nn.MSELoss() \n",
    "\n",
    "# 2. Setup an Optimizer (Stochastic Gradient Descent)\n",
    "# We tell it which parameters to optimize and the learning rate\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e8a0c",
   "metadata": {
    "papermill": {
     "duration": 0.011981,
     "end_time": "2026-01-19T23:55:47.260819",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.248838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. The Clean Training Loop\n",
    "Notice how much cleaner this is. No manual w -= lr * w.grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9acb8e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.286865Z",
     "iopub.status.busy": "2026-01-19T23:55:47.286361Z",
     "iopub.status.idle": "2026-01-19T23:55:47.343495Z",
     "shell.execute_reply": "2026-01-19T23:55:47.342306Z"
    },
    "papermill": {
     "duration": 0.073022,
     "end_time": "2026-01-19T23:55:47.345910",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.272888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 14.744170188903809\n",
      "Epoch: 20 | Loss: 7.181203842163086\n",
      "Epoch: 40 | Loss: 3.5418267250061035\n",
      "Epoch: 60 | Loss: 1.7703059911727905\n",
      "Epoch: 80 | Loss: 0.8976189494132996\n"
     ]
    }
   ],
   "source": [
    "# Create data (same as before)\n",
    "X = torch.randn(100, 1)\n",
    "y_true = 3 * X + 2 + torch.randn(100, 1) * 0.1\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Put model in training mode\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # 2. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "    # 3. Optimizer zero grad (Wipe the slate clean)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Perform Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer (Update the weights)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa7994",
   "metadata": {
    "papermill": {
     "duration": 0.011803,
     "end_time": "2026-01-19T23:55:47.369778",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.357975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Making Predictions (Inference)\n",
    "When testing your model, you must use model.eval() and the inference_mode context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61a2dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.395196Z",
     "iopub.status.busy": "2026-01-19T23:55:47.394846Z",
     "iopub.status.idle": "2026-01-19T23:55:47.402379Z",
     "shell.execute_reply": "2026-01-19T23:55:47.401250Z"
    },
    "papermill": {
     "duration": 0.022821,
     "end_time": "2026-01-19T23:55:47.404471",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.381650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Parameters: OrderedDict({'linear_layer.weight': tensor([[2.3415]]), 'linear_layer.bias': tensor([1.6665])})\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Turns off things like Dropout or Batchnorm (not used here, but good habit)\n",
    "with torch.inference_mode(): # Faster, more memory efficient version of no_grad()\n",
    "    predictions = model(X)\n",
    "\n",
    "print(f\"Learned Parameters: {model.state_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892ebab",
   "metadata": {
    "papermill": {
     "duration": 0.012767,
     "end_time": "2026-01-19T23:55:47.429543",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.416776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 5: Non-Linearity & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced47a8c",
   "metadata": {
    "papermill": {
     "duration": 0.011683,
     "end_time": "2026-01-19T23:55:47.453230",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.441547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The \"Problem\" with Linear Layers\n",
    "If your data isn't a straight line, a linear model will fail. We solve this by adding a non-linear \"trigger\" after a linear layer. The most common one is ReLU (Rectified Linear Unit), which simply turns all negative numbers into zero.\n",
    "\n",
    "## 2. Building a Non-Linear Model\n",
    "We will use a hidden layer and an activation function to build a model that can handle more complex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1e86124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.479798Z",
     "iopub.status.busy": "2026-01-19T23:55:47.479435Z",
     "iopub.status.idle": "2026-01-19T23:55:47.488148Z",
     "shell.execute_reply": "2026-01-19T23:55:47.487051Z"
    },
    "papermill": {
     "duration": 0.024848,
     "end_time": "2026-01-19T23:55:47.490198",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.465350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNet(\n",
      "  (layer_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(), # The \"magic\" non-linear step\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Create an instance (e.g., for data with 2 features, 10 hidden neurons, 1 output)\n",
    "model = SimpleNeuralNet(2, 10, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19fdbd",
   "metadata": {
    "papermill": {
     "duration": 0.012,
     "end_time": "2026-01-19T23:55:47.514452",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.502452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Understanding Binary Cross Entropy (BCE)\n",
    "For regression, we used MSE. For classification (Yes/No, 0/1), we use Binary Cross Entropy. This measures how \"far off\" our predicted probability is from the actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92583235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.539996Z",
     "iopub.status.busy": "2026-01-19T23:55:47.539657Z",
     "iopub.status.idle": "2026-01-19T23:55:47.544710Z",
     "shell.execute_reply": "2026-01-19T23:55:47.543747Z"
    },
    "papermill": {
     "duration": 0.020247,
     "end_time": "2026-01-19T23:55:47.546558",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.526311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Binary Cross Entropy with Logits (more numerically stable)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 2. Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933281d",
   "metadata": {
    "papermill": {
     "duration": 0.012016,
     "end_time": "2026-01-19T23:55:47.571305",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.559289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. The Sigmoid Function\n",
    "Our model outputs \"logits\" (raw numbers). To turn these into probabilities between 0 and 1, we pass them through a Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3fe231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.597473Z",
     "iopub.status.busy": "2026-01-19T23:55:47.597122Z",
     "iopub.status.idle": "2026-01-19T23:55:47.605862Z",
     "shell.execute_reply": "2026-01-19T23:55:47.604611Z"
    },
    "papermill": {
     "duration": 0.024524,
     "end_time": "2026-01-19T23:55:47.608001",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.583477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([-1.2000,  0.5000,  3.0000])\n",
      "Probabilities: tensor([0.2315, 0.6225, 0.9526])\n"
     ]
    }
   ],
   "source": [
    "# Simulated raw output from a model\n",
    "logits = torch.tensor([[-1.2], [0.5], [3.0]])\n",
    "\n",
    "# Convert to probabilities\n",
    "probs = torch.sigmoid(logits)\n",
    "\n",
    "print(f\"Logits: {logits.flatten()}\")\n",
    "print(f\"Probabilities: {probs.flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69403663",
   "metadata": {
    "papermill": {
     "duration": 0.012025,
     "end_time": "2026-01-19T23:55:47.632415",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.620390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 6: Data Pipelines (Dataset & DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64930d23",
   "metadata": {
    "papermill": {
     "duration": 0.012161,
     "end_time": "2026-01-19T23:55:47.657334",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.645173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The Concept: Why Batches?\n",
    "If you have 100,000 rows of data, calculating the gradient for all of them at once is slow and memory-intensive. Instead, we split the data into small chunks (batches), usually of 32, 64, or 128 samples.\n",
    "\n",
    "## 2. The Dataset Class\n",
    "This is where your data \"lives.\" It handles loading and preprocessing.\n",
    "\n",
    "__len__: Returns the total number of items.\n",
    "\n",
    "__getitem__: Returns one specific sample (and its label) given an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "163c0da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.684330Z",
     "iopub.status.busy": "2026-01-19T23:55:47.683982Z",
     "iopub.status.idle": "2026-01-19T23:55:47.692629Z",
     "shell.execute_reply": "2026-01-19T23:55:47.691694Z"
    },
    "papermill": {
     "duration": 0.024239,
     "end_time": "2026-01-19T23:55:47.694434",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.670195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomNumbersDataset(Dataset):\n",
    "    def __init__(self, start, end):\n",
    "        # Create some dummy data: X is the number, y is the number * 2\n",
    "        self.samples = torch.arange(start, end, dtype=torch.float32).reshape(-1, 1)\n",
    "        self.labels = self.samples * 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]\n",
    "\n",
    "# Instantiate\n",
    "dataset = CustomNumbersDataset(0, 100)\n",
    "print(f\"Dataset length: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1b96a",
   "metadata": {
    "papermill": {
     "duration": 0.012111,
     "end_time": "2026-01-19T23:55:47.718864",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.706753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. The DataLoader Class\n",
    "The DataLoader is an iterable. It wraps the Dataset and automatically manages batching, shuffling, and even using multiple CPU cores to load data faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d6c0e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.745137Z",
     "iopub.status.busy": "2026-01-19T23:55:47.744695Z",
     "iopub.status.idle": "2026-01-19T23:55:47.756002Z",
     "shell.execute_reply": "2026-01-19T23:55:47.754945Z"
    },
    "papermill": {
     "duration": 0.027236,
     "end_time": "2026-01-19T23:55:47.758171",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.730935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Features shape: torch.Size([8, 1])\n",
      "Batch Labels shape: torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# Batch size of 8. Shuffle=True is vital for training!\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Let's look at one batch\n",
    "first_batch_features, first_batch_labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch Features shape: {first_batch_features.shape}\") # [8, 1]\n",
    "print(f\"Batch Labels shape: {first_batch_labels.shape}\")     # [8, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dad1c",
   "metadata": {
    "papermill": {
     "duration": 0.014702,
     "end_time": "2026-01-19T23:55:47.785556",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.770854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. The Updated Training Loop\n",
    "Now, our training loop has a \"nested\" loop. We loop through epochs (entire dataset), and inside each epoch, we loop through batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1877a489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.811766Z",
     "iopub.status.busy": "2026-01-19T23:55:47.811398Z",
     "iopub.status.idle": "2026-01-19T23:55:47.840869Z",
     "shell.execute_reply": "2026-01-19T23:55:47.840090Z"
    },
    "papermill": {
     "duration": 0.045435,
     "end_time": "2026-01-19T23:55:47.843171",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.797736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed.\n",
      "Epoch 2 completed.\n",
      "Epoch 3 completed.\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    # Loop through batches\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        # 2. Loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        # 3. Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c35e0",
   "metadata": {
    "papermill": {
     "duration": 0.013056,
     "end_time": "2026-01-19T23:55:47.868862",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.855806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 7: Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ebb2f",
   "metadata": {
    "papermill": {
     "duration": 0.012524,
     "end_time": "2026-01-19T23:55:47.894750",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.882226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## A CNN typically consists of three main operations:\n",
    "\n",
    "Convolution (nn.Conv2d): Slides a small window (filter) over the image to find edges, textures, or shapes.\n",
    "\n",
    "Activation (nn.ReLU): Adds non-linearity.\n",
    "\n",
    "Pooling (nn.MaxPool2d): Reduces the size of the image, keeping only the most important information (the \"strongest\" pixels).\n",
    "\n",
    "## 2. The Convolutional Layer (Conv2d)\n",
    "When you define a Conv2d layer, you need to know:\n",
    "\n",
    "in_channels: 1 for Grayscale, 3 for RGB (Color).\n",
    "\n",
    "out_channels: Number of filters (patterns) the model will try to learn.\n",
    "\n",
    "kernel_size: The size of the sliding window (usually 3x3 or 5x5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75a62255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.921291Z",
     "iopub.status.busy": "2026-01-19T23:55:47.920904Z",
     "iopub.status.idle": "2026-01-19T23:55:47.939320Z",
     "shell.execute_reply": "2026-01-19T23:55:47.938276Z"
    },
    "papermill": {
     "duration": 0.034465,
     "end_time": "2026-01-19T23:55:47.941500",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.907035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 3, 64, 64])\n",
      "Shape after convolution: torch.Size([1, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create a dummy \"image\": [Batch, Color_Channels, Height, Width]\n",
    "dummy_image = torch.randn(1, 3, 64, 64) \n",
    "\n",
    "# Define a convolution layer\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Apply it\n",
    "output = conv_layer(dummy_image)\n",
    "print(f\"Original shape: {dummy_image.shape}\")\n",
    "print(f\"Shape after convolution: {output.shape}\") # Height/Width stay same due to padding=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b764b",
   "metadata": {
    "papermill": {
     "duration": 0.012898,
     "end_time": "2026-01-19T23:55:47.966920",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.954022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Building a TinyVGG Style CNN\n",
    "This is a famous architecture for learning image classification from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95126292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:47.993939Z",
     "iopub.status.busy": "2026-01-19T23:55:47.993160Z",
     "iopub.status.idle": "2026-01-19T23:55:48.001463Z",
     "shell.execute_reply": "2026-01-19T23:55:48.000415Z"
    },
    "papermill": {
     "duration": 0.024497,
     "end_time": "2026-01-19T23:55:48.003812",
     "exception": false,
     "start_time": "2026-01-19T23:55:47.979315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2) # Halves the height and width\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), # Turns the 2D feature maps into a 1D vector\n",
    "            # The input features here depend on the image size after pooling\n",
    "            nn.Linear(in_features=hidden_units * 32 * 32, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Model for a 64x64 RGB image with 2 classes\n",
    "model = TinyVGG(input_shape=3, hidden_units=10, output_shape=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979c6b6",
   "metadata": {
    "papermill": {
     "duration": 0.012343,
     "end_time": "2026-01-19T23:55:48.028682",
     "exception": false,
     "start_time": "2026-01-19T23:55:48.016339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Flattening: The Bridge\n",
    "The most common error in CNNs is the transition between the Convolutional layers (3D) and the Linear layers (1D). nn.Flatten() takes a tensor of shape (Batch, Channels, Height, Width) and squashes it into (Batch, Channels * Height * Width)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87699b3f",
   "metadata": {
    "papermill": {
     "duration": 0.012227,
     "end_time": "2026-01-19T23:55:48.053327",
     "exception": false,
     "start_time": "2026-01-19T23:55:48.041100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 8: Transfer Learning & Pre-trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d52500",
   "metadata": {
    "papermill": {
     "duration": 0.012162,
     "end_time": "2026-01-19T23:55:48.077994",
     "exception": false,
     "start_time": "2026-01-19T23:55:48.065832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The Strategy\n",
    "Instead of starting with random weights, we use a model that already knows how to see (recognize edges, eyes, wheels, etc.).\n",
    "\n",
    "Pick a backbone: Use a pre-trained model (e.g., ResNet, EfficientNet).\n",
    "\n",
    "Freeze it: Prevent the pre-trained weights from changing during initial training.\n",
    "\n",
    "Replace the \"Head\": Swap the final linear layer with one that fits your specific number of classes.\n",
    "\n",
    "## 2. Loading a Pre-trained Model\n",
    "PyTorch makes this easy through torchvision.models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a18ae6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:48.106698Z",
     "iopub.status.busy": "2026-01-19T23:55:48.105644Z",
     "iopub.status.idle": "2026-01-19T23:55:50.361834Z",
     "shell.execute_reply": "2026-01-19T23:55:50.360558Z"
    },
    "papermill": {
     "duration": 2.274244,
     "end_time": "2026-01-19T23:55:50.364368",
     "exception": false,
     "start_time": "2026-01-19T23:55:48.090124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 44.7M/44.7M [00:00<00:00, 55.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ResNet Classifier: Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "# 1. Get the pre-trained weights\n",
    "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "model = torchvision.models.resnet18(weights=weights)\n",
    "\n",
    "# 2. Freeze all base layers (Parameters won't update during backprop)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f\"Original ResNet Classifier: {model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d6911",
   "metadata": {
    "papermill": {
     "duration": 0.012899,
     "end_time": "2026-01-19T23:55:50.391196",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.378297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Modifying the Classifier\n",
    "The original ResNet was trained on 1,000 classes. If you only want to classify \"Dogs vs. Cats,\" you change the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2495080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.419262Z",
     "iopub.status.busy": "2026-01-19T23:55:50.418365Z",
     "iopub.status.idle": "2026-01-19T23:55:50.425145Z",
     "shell.execute_reply": "2026-01-19T23:55:50.424054Z"
    },
    "papermill": {
     "duration": 0.023341,
     "end_time": "2026-01-19T23:55:50.427373",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.404032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Classifier: Linear(in_features=512, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 3. Replace the last layer (fc = fully connected)\n",
    "# We know ResNet18's last layer has 512 input features\n",
    "model.fc = nn.Linear(in_features=512, out_features=2) \n",
    "\n",
    "# Now, only the weights in model.fc will be trained!\n",
    "print(f\"New Classifier: {model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d165930",
   "metadata": {
    "papermill": {
     "duration": 0.012864,
     "end_time": "2026-01-19T23:55:50.454219",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.441355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Data Transformation\n",
    "When using pre-trained models, you must use the same preprocessing (scaling, cropping, normalization) that the original model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17477866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.481625Z",
     "iopub.status.busy": "2026-01-19T23:55:50.481269Z",
     "iopub.status.idle": "2026-01-19T23:55:50.486614Z",
     "shell.execute_reply": "2026-01-19T23:55:50.485619Z"
    },
    "papermill": {
     "duration": 0.021637,
     "end_time": "2026-01-19T23:55:50.488797",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.467160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Transforms:\n",
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get the transforms required by the weights\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "print(f\"Required Transforms:\\n{preprocess}\")\n",
    "# This will show you things like: Resize(size=[224]), Normalize(mean=[0.485...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75b091",
   "metadata": {
    "papermill": {
     "duration": 0.012779,
     "end_time": "2026-01-19T23:55:50.514823",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.502044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 9: Saving, Loading, and the state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006ed2a",
   "metadata": {
    "papermill": {
     "duration": 0.012743,
     "end_time": "2026-01-19T23:55:50.540431",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.527688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In PyTorch, we don't usually save the entire model object (the \"body\"). Instead, we save the state_dict (the \"brain\"). This is a Python dictionary that maps each layer to its learned weight and bias tensors.\n",
    "\n",
    "## 1. Inspecting the state_dict\n",
    "Before saving, its helpful to see whats actually inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fcae1ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.568136Z",
     "iopub.status.busy": "2026-01-19T23:55:50.567776Z",
     "iopub.status.idle": "2026-01-19T23:55:50.577746Z",
     "shell.execute_reply": "2026-01-19T23:55:50.576658Z"
    },
    "papermill": {
     "duration": 0.026476,
     "end_time": "2026-01-19T23:55:50.579739",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.553263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model's State Dict Keys ---\n",
      "0.weight \t shape: torch.Size([5, 3])\n",
      "0.bias \t shape: torch.Size([5])\n",
      "2.weight \t shape: torch.Size([1, 5])\n",
      "2.bias \t shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create a simple model from scratch\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "print(\"--- Model's State Dict Keys ---\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(f\"{param_tensor} \\t shape: {model.state_dict()[param_tensor].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348521a",
   "metadata": {
    "papermill": {
     "duration": 0.013036,
     "end_time": "2026-01-19T23:55:50.606122",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.593086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Saving the Weights\n",
    "We use torch.save(). While you can name the file anything, the community standard is .pt or .pth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "423354c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.634586Z",
     "iopub.status.busy": "2026-01-19T23:55:50.633677Z",
     "iopub.status.idle": "2026-01-19T23:55:50.643387Z",
     "shell.execute_reply": "2026-01-19T23:55:50.642300Z"
    },
    "papermill": {
     "duration": 0.026101,
     "end_time": "2026-01-19T23:55:50.645379",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.619278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/09_model_scratch.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Setup directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create save path\n",
    "MODEL_NAME = \"09_model_scratch.pth\"\n",
    "SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save only the state_dict\n",
    "print(f\"Saving model to: {SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf2e6df",
   "metadata": {
    "papermill": {
     "duration": 0.013357,
     "end_time": "2026-01-19T23:55:50.672251",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.658894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Loading the Weights\n",
    "To load, you must first recreate the exact same architecture (the \"body\"). You cannot load weights into a model with different layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "011a6961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.700759Z",
     "iopub.status.busy": "2026-01-19T23:55:50.700049Z",
     "iopub.status.idle": "2026-01-19T23:55:50.708705Z",
     "shell.execute_reply": "2026-01-19T23:55:50.707649Z"
    },
    "papermill": {
     "duration": 0.025002,
     "end_time": "2026-01-19T23:55:50.710493",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.685491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model class again (must be identical structure)\n",
    "loaded_model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# 2. Load the file from disk\n",
    "saved_weights = torch.load(f=SAVE_PATH)\n",
    "\n",
    "# 3. Load the weights into the model instance\n",
    "loaded_model.load_state_dict(saved_weights)\n",
    "\n",
    "print(\"Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d351f4",
   "metadata": {
    "papermill": {
     "duration": 0.01335,
     "end_time": "2026-01-19T23:55:50.738184",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.724834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Moving to Evaluation Mode\n",
    "This is the part most beginners forget. When you load a model to make predictions, you must call .eval(). This turns off layers like Dropout or BatchNorm that behave differently during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ee266bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.766286Z",
     "iopub.status.busy": "2026-01-19T23:55:50.765939Z",
     "iopub.status.idle": "2026-01-19T23:55:50.775327Z",
     "shell.execute_reply": "2026-01-19T23:55:50.774248Z"
    },
    "papermill": {
     "duration": 0.025868,
     "end_time": "2026-01-19T23:55:50.777373",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.751505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-0.8423]])\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "\n",
    "with torch.inference_mode(): # Faster, uses less memory than no_grad()\n",
    "    dummy_input = torch.randn(1, 3)\n",
    "    prediction = loaded_model(dummy_input)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b0e8e",
   "metadata": {
    "papermill": {
     "duration": 0.013284,
     "end_time": "2026-01-19T23:55:50.804049",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.790765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 10: NLP  Tokens, Embeddings, and RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ed2f7",
   "metadata": {
    "papermill": {
     "duration": 0.013318,
     "end_time": "2026-01-19T23:55:50.830488",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.817170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Tokenization: Turning Words into IDs\n",
    "The first step is breaking a sentence into \"tokens\" (words or characters) and assigning each unique token a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "349f5cd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.858743Z",
     "iopub.status.busy": "2026-01-19T23:55:50.858321Z",
     "iopub.status.idle": "2026-01-19T23:55:50.866790Z",
     "shell.execute_reply": "2026-01-19T23:55:50.865844Z"
    },
    "papermill": {
     "duration": 0.025192,
     "end_time": "2026-01-19T23:55:50.868989",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.843797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Mapping: {'love': 0, 'scratch': 1, 'i': 2, 'from': 3, 'building': 4}\n",
      "Integer Sequence: tensor([2, 0, 4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Our raw data\n",
    "text = \"i love building from scratch\"\n",
    "words = text.split()\n",
    "\n",
    "# Create a vocabulary mapping\n",
    "vocab = {word: i for i, word in enumerate(set(words))}\n",
    "print(f\"Vocab Mapping: {vocab}\")\n",
    "\n",
    "# Convert sentence to integers\n",
    "sequence = torch.tensor([vocab[w] for w in words])\n",
    "print(f\"Integer Sequence: {sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b3047",
   "metadata": {
    "papermill": {
     "duration": 0.013431,
     "end_time": "2026-01-19T23:55:50.896711",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.883280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. The Embedding Layer (nn.Embedding)\n",
    "An integer like 4 doesn't tell the model anything about a word's meaning. We use Embeddingstrainable vectors where words with similar meanings end up close to each other in mathematical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34438142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.925252Z",
     "iopub.status.busy": "2026-01-19T23:55:50.924917Z",
     "iopub.status.idle": "2026-01-19T23:55:50.932965Z",
     "shell.execute_reply": "2026-01-19T23:55:50.931886Z"
    },
    "papermill": {
     "duration": 0.024649,
     "end_time": "2026-01-19T23:55:50.934907",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.910258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Shape: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Assume vocab size of 10, and we want each word to be a 5-number vector\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
    "\n",
    "# Turn our sequence of IDs into a sequence of vectors\n",
    "embedded_sentence = embedding(sequence)\n",
    "\n",
    "print(f\"Sequence Shape: {embedded_sentence.shape}\") # [5 words, 5 dimensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ad7e8",
   "metadata": {
    "papermill": {
     "duration": 0.013834,
     "end_time": "2026-01-19T23:55:50.962069",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.948235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. The Recurrent Neural Network (RNN)\n",
    "Standard models process all inputs at once. RNNs process words one-by-one, maintaining a Hidden State (memory) that carries information from the beginning of the sentence to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "782fb60e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:50.990795Z",
     "iopub.status.busy": "2026-01-19T23:55:50.990423Z",
     "iopub.status.idle": "2026-01-19T23:55:51.006446Z",
     "shell.execute_reply": "2026-01-19T23:55:51.005430Z"
    },
    "papermill": {
     "duration": 0.032622,
     "end_time": "2026-01-19T23:55:51.008443",
     "exception": false,
     "start_time": "2026-01-19T23:55:50.975821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Memory (Hidden State) Shape: torch.Size([1, 1, 12])\n"
     ]
    }
   ],
   "source": [
    "# input_size=5 (embedding dim), hidden_size=12 (size of the 'memory' vector)\n",
    "rnn = nn.RNN(input_size=5, hidden_size=12, batch_first=True)\n",
    "\n",
    "# Add a batch dimension [Batch, Seq_Len, Features]\n",
    "input_data = embedded_sentence.unsqueeze(0) \n",
    "\n",
    "# output: hidden states for every word\n",
    "# hidden: the final 'summary' memory of the whole sentence\n",
    "output, hidden = rnn(input_data)\n",
    "\n",
    "print(f\"Final Memory (Hidden State) Shape: {hidden.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bd6b8",
   "metadata": {
    "papermill": {
     "duration": 0.013538,
     "end_time": "2026-01-19T23:55:51.035365",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.021827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lecture 11: The Transformer & Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1793b59",
   "metadata": {
    "papermill": {
     "duration": 0.013305,
     "end_time": "2026-01-19T23:55:51.061958",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.048653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. The Core Idea: Attention\n",
    "In the sentence: \"The animal didn't cross the street because it was too tired,\" Self-Attention allows the model to link the word \"it\" back to \"animal\". If the sentence ended in \"because it was too wide,\" the model would link \"it\" to \"street\".\n",
    "\n",
    "## 2. Multi-Head Attention in PyTorch\n",
    "PyTorch provides a powerful nn.MultiheadAttention layer, but for our \"from scratch\" path, well see how it fits into a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9466df37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:51.091877Z",
     "iopub.status.busy": "2026-01-19T23:55:51.091430Z",
     "iopub.status.idle": "2026-01-19T23:55:51.109680Z",
     "shell.execute_reply": "2026-01-19T23:55:51.108606Z"
    },
    "papermill": {
     "duration": 0.036044,
     "end_time": "2026-01-19T23:55:51.112290",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.076246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Output Shape: torch.Size([10, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Parameters\n",
    "embed_dim = 128  # Dimension of our word vectors\n",
    "num_heads = 8    # Number of \"attention heads\" looking at different patterns\n",
    "\n",
    "# Define the layer\n",
    "attention_layer = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "\n",
    "# Create dummy input: [Sequence_Length, Batch_Size, Embed_Dim]\n",
    "# (Note: Transformers often expect Seq_Len first unless batch_first=True)\n",
    "query = torch.randn(10, 1, 128)\n",
    "key = query\n",
    "value = query\n",
    "\n",
    "# attn_output: the new vectors for each word, informed by their neighbors\n",
    "attn_output, attn_weights = attention_layer(query, key, value)\n",
    "\n",
    "print(f\"Attention Output Shape: {attn_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb15db",
   "metadata": {
    "papermill": {
     "duration": 0.014023,
     "end_time": "2026-01-19T23:55:51.140913",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.126890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. The Transformer Block\n",
    "A Transformer isn't just attention; its a stack of Attention + Feed Forward layers with \"Residual Connections\" (skipping layers) to help gradients flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9138da5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:55:51.170250Z",
     "iopub.status.busy": "2026-01-19T23:55:51.169500Z",
     "iopub.status.idle": "2026-01-19T23:55:51.180407Z",
     "shell.execute_reply": "2026-01-19T23:55:51.179075Z"
    },
    "papermill": {
     "duration": 0.027522,
     "end_time": "2026-01-19T23:55:51.182354",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.154832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleTransformerBlock(\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleTransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Attention + Residual Connection\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out) # Add & Norm\n",
    "        \n",
    "        # 2. Feed Forward + Residual Connection\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + ff_out) # Add & Norm\n",
    "        return x\n",
    "\n",
    "model_block = SimpleTransformerBlock(128, 8)\n",
    "print(model_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50464f16",
   "metadata": {
    "papermill": {
     "duration": 0.014477,
     "end_time": "2026-01-19T23:55:51.210407",
     "exception": false,
     "start_time": "2026-01-19T23:55:51.195930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Positional Encoding\n",
    "Since Transformers see the whole sentence at once, they don't naturally know the order of words (unlike RNNs). We have to \"inject\" the position of each word into the embedding using math (sines and cosines)."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.781905,
   "end_time": "2026-01-19T23:55:53.932056",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-19T23:55:29.150151",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
